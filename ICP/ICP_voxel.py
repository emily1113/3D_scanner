import os
import re
import time
import numpy as np
import open3d as o3d
import pandas as pd
from sklearn.neighbors import NearestNeighbors
from datetime import datetime  # ğŸ”¹ æ–°å¢ï¼šé¡¯ç¤ºç³»çµ±æ™‚é–“ç”¨

# ------------------ è‡ªè¨‚é«”ç´ ä¸‹æ¡æ¨£å‡½å¼ ------------------

def voxel_downsample(point_cloud, voxel_size):
    """
    é«”ç´ ä¸‹æ¡æ¨£ï¼šåˆ©ç”¨æŒ‡å®šçš„é«”ç´ å¤§å°å°é»é›²é€²è¡Œä¸‹æ¡æ¨£è™•ç†ï¼Œ
    å°‡åŒä¸€é«”ç´ ä¸­çš„å¤šå€‹é»æ›¿æ›æˆè©²é«”ç´ æ‰€æœ‰é»çš„é‡å¿ƒã€‚
    """
    min_bounds = np.min(point_cloud, axis=0)
    voxel_indices = np.floor((point_cloud - min_bounds) / voxel_size).astype(np.int32)
    voxel_dict = {}
    for i, voxel_idx in enumerate(voxel_indices):
        key = tuple(voxel_idx)
        voxel_dict.setdefault(key, []).append(point_cloud[i])
    downsampled_points = []
    for points in voxel_dict.values():
        points = np.array(points)
        centroid = np.mean(points, axis=0)
        downsampled_points.append(centroid)
    return np.array(downsampled_points)

# ------------------ è‡ªè¨‚æ³•å‘é‡è¨ˆç®—å‡½å¼ ------------------

def compute_normals(points, k=15, view_point=np.array([0, 0, 0], dtype=np.float64), tolerance=1e-8):
    """
    æ ¹æ“šé»é›²è³‡æ–™è¨ˆç®—æ¯å€‹é»çš„æ³•å‘é‡ï¼Œä¸¦çµ±ä¸€å–æ­£æ–¹å‘ï¼ŒåŒæ™‚ä¿è­‰æ•¸å€¼ç©©å®šæ€§ã€‚
    
    :param points: (N, 3) numpy é™£åˆ—ï¼Œè³‡æ–™é¡å‹ç‚º np.float64ï¼Œä»£è¡¨ N å€‹é»çš„ x, y, z åº§æ¨™ã€‚
    :param k: ç”¨æ–¼è¨ˆç®—æ³•å‘é‡çš„é„°åŸŸé»æ•¸é‡ã€‚
    :param view_point: åƒè€ƒè¦–é»ï¼Œæ‰€æœ‰æ³•å‘é‡éƒ½å°‡çµ±ä¸€æŒ‡å‘è©²é»çš„å¤–å´ï¼Œè³‡æ–™é¡å‹ç‚º np.float64ã€‚
    :param tolerance: ç•¶å‘é‡æ¨¡é•·ä½æ–¼æ­¤å®¹å¿å€¼æ™‚ï¼Œèªç‚ºå‘é‡ç‚º 0ï¼Œé¿å…é™¤ä»¥ 0 çš„æƒ…æ³ã€‚
    :return: (N, 3) numpy é™£åˆ—ï¼Œæ¯ä¸€åˆ—ç‚ºæ­£è¦åŒ–ä¸¦çµ±ä¸€æ–¹å‘å¾Œçš„æ³•å‘é‡ï¼Œè³‡æ–™é¡å‹ç‚º np.float64ã€‚
    """
    n_points = points.shape[0]
    normals = np.zeros_like(points, dtype=np.float64)
    nbrs = NearestNeighbors(n_neighbors=k, algorithm='auto').fit(points)
    distances, indices = nbrs.kneighbors(points)
    for i in range(n_points):
        neighbor_pts = points[indices[i]]
        mean = neighbor_pts.mean(axis=0)
        cov = np.dot((neighbor_pts - mean).T, (neighbor_pts - mean)) / k
        eigenvalues, eigenvectors = np.linalg.eigh(cov)
        normal = eigenvectors[:, 0]
        norm_val = np.linalg.norm(normal)
        if norm_val > tolerance:
            normal = normal / norm_val
        else:
            normal = np.array([0, 0, 0], dtype=np.float64)
        if np.dot(points[i] - view_point, normal) < 0:
            normal = -normal
        normals[i] = normal
    return normals

# ------------------ é»é›²é è™•ç†å‡½å¼ ------------------

def custom_preprocess_point_cloud(point_cloud, voxel_size):
    """
    ä½¿ç”¨è‡ªè¨‚çš„ voxel_downsample å° Open3D é»é›²é€²è¡Œä¸‹æ¡æ¨£è™•ç†ï¼Œ
    ä¸¦åˆ©ç”¨ compute_normals è¨ˆç®—ä¸‹æ¡æ¨£å¾Œçš„æ³•å‘é‡ã€‚
    
    åƒæ•¸:
      point_cloud: Open3D PointCloud ç‰©ä»¶
      voxel_size: floatï¼Œä¸‹æ¡æ¨£è§£æåº¦
      
    è¿”å›:
      ä¸‹æ¡æ¨£å¾Œï¼ŒåŒ…å«é»èˆ‡æ³•å‘é‡è³‡è¨Šçš„ Open3D PointCloud ç‰©ä»¶
    """
    points = np.asarray(point_cloud.points).astype(np.float64)
    down_points = voxel_downsample(points, voxel_size)
    normals = compute_normals(down_points, k=15, view_point=np.array([0, 0, 0], dtype=np.float64))
    down_pcd = o3d.geometry.PointCloud()
    down_pcd.points = o3d.utility.Vector3dVector(down_points)
    down_pcd.normals = o3d.utility.Vector3dVector(normals)
    return down_pcd

# ------------------ é…æº–èˆ‡åˆä½µå‡½å¼ ------------------

def refine_registration(source, target, initial_transformation, distance_threshold):
    """
    ä½¿ç”¨ ICP (é»åˆ°å¹³é¢) é€²è¡Œç²¾ç´°é…æº–
    """
    result_icp = o3d.pipelines.registration.registration_icp(
        source, target,
        max_correspondence_distance=distance_threshold,
        init=initial_transformation,
        estimation_method=o3d.pipelines.registration.TransformationEstimationPointToPlane()
    )
    return result_icp

def process_pair(source_file, target_file, voxel_size, refined_distance_threshold, downsample=True):
    """
    è®€å–å…©å€‹é»é›²æª”æ¡ˆï¼Œ
    æ ¹æ“š downsample åƒæ•¸æ±ºå®šæ˜¯å¦ä½¿ç”¨è‡ªè¨‚é«”ç´ ä¸‹æ¡æ¨£ï¼ˆä¸¦è¨ˆç®—æ³•å‘é‡ï¼‰ï¼Œ
    å†é€²è¡Œ ICP é…æº–ï¼Œä¸¦åˆä½µé…æº–å¾Œçš„é»é›²ï¼ˆæœ€çµ‚çµ±ä¸€è‘—è‰²ç‚ºç´…è‰²ï¼‰ã€‚
    
    è‹¥ä»»ä¸€é»é›²é»æ•¸è¶…é 500,000ï¼Œå‰‡å¼·åˆ¶ä¸‹æ¡æ¨£ã€‚
    
    è¿”å›:
        åˆä½µå¾Œçš„ Open3D é»é›²ç‰©ä»¶
    """
    source_pcd = o3d.io.read_point_cloud(source_file)
    target_pcd = o3d.io.read_point_cloud(target_file)
    if not source_pcd.has_normals():
        source_pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size * 2, max_nn=30))
    if not target_pcd.has_normals():
        target_pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size * 2, max_nn=30))
    if not downsample:
        if len(source_pcd.points) > 500000 or len(target_pcd.points) > 500000:
            print("ç™¼ç¾é»é›²é»æ•¸è¶…é 500,000ï¼Œå¼·åˆ¶ä¸‹æ¡æ¨£ï¼")
            downsample = True
    if downsample:
        src_before = len(source_pcd.points)
        source_proc = custom_preprocess_point_cloud(source_pcd, voxel_size)
        src_after = len(source_proc.points)
        print(f"[Custom Voxel Downsampling Source] {source_file}ï¼š{src_before} -> {src_after}")
        tgt_before = len(target_pcd.points)
        target_proc = custom_preprocess_point_cloud(target_pcd, voxel_size)
        tgt_after = len(target_proc.points)
        print(f"[Custom Voxel Downsampling Target] {target_file}ï¼š{tgt_before} -> {tgt_after}")
    else:
        source_proc = source_pcd
        target_proc = target_pcd
    if not source_proc.has_normals():
        source_proc.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size*2, max_nn=30))
    if not target_proc.has_normals():
        target_proc.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size*2, max_nn=30))
    initial_transformation = np.eye(4)
    result_icp = refine_registration(source_proc, target_proc, initial_transformation, refined_distance_threshold)
    source_proc.transform(result_icp.transformation)
    merged_pcd = source_proc + target_proc
    merged_pcd.paint_uniform_color([1, 0, 0])
    return merged_pcd

def get_new_filename(file1, file2):
    """
    æª”æ¡ˆå‘½åè¦å‰‡ï¼š
    è‹¥ file1 ç‚º "A_B.ply" è€Œ file2 ç‚º "B_C.ply"ï¼Œå‰‡å›å‚³ "A_C.ply"
    """
    pattern = r"(\d{5})_(\d{5})\.ply"
    m1 = re.match(pattern, file1)
    m2 = re.match(pattern, file2)
    if m1 and m2:
        left = m1.group(1)
        right = m2.group(2)
        return f"{left}_{right}.ply"
    else:
        return f"merged_{file1}_{file2}.ply"

# ------------------ ä¸»ç¨‹åº ------------------

if __name__ == "__main__":
    # ğŸ”¹ é¡¯ç¤ºåŒ¹é…é–‹å§‹ç³»çµ±æ™‚é–“
    print("é…æº–é–‹å§‹æ™‚é–“ï¼š", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))

    # åƒæ•¸è¨­å®š
    voxel_size = 0.5  # è‡ªè¨‚é«”ç´ ä¸‹æ¡æ¨£è§£æåº¦ï¼ˆä¾éœ€æ±‚èª¿æ•´ï¼‰
    refined_distance_threshold = voxel_size * 1.5
    base_folder = r"C:\Users\user\Desktop\PointCloud\red\furiren_ALL"
    records = []

    # ------------------ ç¬¬ä¸€éšæ®µ ------------------
    output_folder = os.path.join(base_folder, "2")
    os.makedirs(output_folder, exist_ok=True)
    total_files = 77
    for i in range(total_files - 1):
        source_file = os.path.join(base_folder, f"normals_point_cloud_{i:05d}.ply")
        target_file = os.path.join(base_folder, f"normals_point_cloud_{i+1:05d}.ply")
        if not os.path.exists(source_file) or not os.path.exists(target_file):
            print(f"æª”æ¡ˆä¸å­˜åœ¨ï¼Œç•¥é: {source_file} æˆ– {target_file}")
            continue
        print(f"ç¬¬ä¸€éšæ®µé…æº–: {source_file} èˆ‡ {target_file}")
        start_time = time.time()
        merged_pcd = process_pair(source_file, target_file, voxel_size, refined_distance_threshold, downsample=True)
        end_time = time.time()
        merge_time = end_time - start_time
        output_filename = f"{i:05d}_{i+1:05d}.ply"
        output_path = os.path.join(output_folder, output_filename)
        o3d.io.write_point_cloud(output_path, merged_pcd)
        print(f"å„²å­˜è‡³: {output_path}ï¼Œè€—æ™‚: {merge_time:.2f} ç§’")
        records.append({
            "Stage": 2,
            "Filename": output_filename,
            "PointCount": len(merged_pcd.points),
            "MergeTime(s)": merge_time
        })

    # ------------------ å¾ŒçºŒéšæ®µè¿­ä»£ ------------------
    stage = 2
    merge_counter = 1
    while True:
        current_folder = os.path.join(base_folder, str(stage))
        files = sorted([f for f in os.listdir(current_folder) if f.endswith(".ply")])
        num_files = len(files)
        print(f"éšæ®µ {stage} æª”æ¡ˆæ•¸ï¼š {num_files}")
        if num_files <= 1:
            print("åªå‰©ä¸‹ä¸€å€‹æª”æ¡ˆï¼ŒçµæŸåˆä½µï¼")
            break
        next_stage = stage + 1
        next_folder = os.path.join(base_folder, str(next_stage))
        os.makedirs(next_folder, exist_ok=True)
        for i in range(num_files - 1):
            file1 = files[i]
            file2 = files[i+1]
            source_file = os.path.join(current_folder, file1)
            target_file = os.path.join(current_folder, file2)
            ds_flag = True if merge_counter == 1 or merge_counter % 3 == 0 else False
            print(f"éšæ®µ {stage} é…æº–: {source_file} èˆ‡ {target_file} (downsample={ds_flag})")
            start_time = time.time()
            merged_pcd = process_pair(source_file, target_file, voxel_size, refined_distance_threshold, downsample=ds_flag)
            end_time = time.time()
            merge_time = end_time - start_time
            new_filename = get_new_filename(file1, file2)
            output_path = os.path.join(next_folder, new_filename)
            o3d.io.write_point_cloud(output_path, merged_pcd)
            print(f"â†’ è¼¸å‡º: {output_path}ï¼Œè€—æ™‚: {merge_time:.2f} ç§’")
            records.append({
                "Stage": next_stage,
                "Filename": new_filename,
                "PointCount": len(merged_pcd.points),
                "MergeTime(s)": merge_time
            })
            merge_counter += 1
        stage = next_stage

    # ------------------ é¡¯ç¤ºæœ€çµ‚æˆæœ ------------------
    final_folder = os.path.join(base_folder, str(stage))
    final_files = [f for f in os.listdir(final_folder) if f.endswith(".ply")]
    if final_files:
        final_file = os.path.join(final_folder, final_files[0])
        print("æœ€çµ‚æˆæœæª”æ¡ˆ:", final_file)
        final_pcd = o3d.io.read_point_cloud(final_file)
        o3d.visualization.draw_geometries([final_pcd], window_name="æœ€çµ‚æˆæœ")
    else:
        print("ç„¡æœ€çµ‚æˆæœæª”æ¡ˆå¯é¡¯ç¤ºã€‚")

    print("æ‰€æœ‰éšæ®µåˆä½µå®Œæˆï¼")
    # ğŸ”¹ é¡¯ç¤ºåŒ¹é…çµæŸç³»çµ±æ™‚é–“
    print("é…æº–çµæŸæ™‚é–“ï¼š", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))

    # ------------------ è¼¸å‡º Excel è¨˜éŒ„ ------------------
    df = pd.DataFrame(records, columns=["Stage", "Filename", "PointCount", "MergeTime(s)"])
    excel_log_file = os.path.join(base_folder, "merge_log.xlsx")
    df.to_excel(excel_log_file, index=False)
    print("Merge log saved to:", excel_log_file)
